---
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
setwd('~/Github/developmental_disorders_SL/')
library(tidyverse)
library(naniar)
library(knitr)
library(ggthemes)
library(patchwork)
d = read_csv('data/df.csv')
v1 = read_tsv('varimp1.tsv')
v2 = read_tsv('varimp2.tsv')
```

Hát nyilván a sentence repetition és az expressive vocabulary a két fontos kimeneti változó, lol

## A kérdés

Tehát én azt hiszem, hogy a kérdés az, mennyire tudjuk megjósolni a két statisztikai tanulásos változót a többiből. A két statisztikai tanulásos változó:

- sent_rep
- expr_vocab

A prediktorok:

- IQ
- group
- digit_span_forward
- digit_span_backward
- PS_vis_RT_med
- PS_ac_RT_med
- n_back_2_mean_score
- AGL_offline
- AGL_medRT_diff

## Hiányzó mérések

Az a gond, hogy hiányoznak mérések:

```{r missing_values, fig.width = 8, fig.height = 4}
vis_miss(d, sort_miss = T)

c1 = d |> 
  na.omit() |> 
  count(group, name = "complete cases")
c2 = d |> count(group, name = "all observations")
c3 = left_join(c2,c1, by = join_by(group)) |> 
  mutate(`% missing` = 100-`complete cases`/`all observations`*100)
```

Ez nem sok, viszont azt jelenti, hogy a gyerekek kétharmadánál van meg minden mérés. Ez a csoportok között sem oszlik meg szabályosan:

```{r missing_values2}
kable(c3,'simple', digits = 0)
```

## Random forest

Ha lineáris modellt használunk, akkor lesz p érték, amit szeretnek a pszichológusok, viszont csak az adatok kétharmadát-háromnegyedét tudjuk használni, ami nem jó.

Ehelyett építettem egy random forest modellt az adatokra. A random forest véletlenszerűen húzgál ki sorokat és oszlopokat az adatokból, és ezekre épít regressziós fákat. Mondjuk kiválaszt ötven gyereket és két prediktort, aztán harminc gyereket és három prediktort, és így tovább. Ezután ebből a sok pici modellből átlagolja ki, hogy melyik prediktor jósolja jól a kimeneti változót a teljes adathalmazban.

Két modellt építettem. Az első kimenete a `sent_rep`, a másodiké az `expr_vocab`. A modelleken a gépi tanulásban elvárt módon tekergettem a hiperparamétereket (hány sort és oszlopot húz ki egy kis modell, milyen fát épít, stb), de ez nagyon sokat nem számított.

A modellek legfontosabb kimenete a variable importance, hogy melyik prediktor jósolja meg jól a kimenetet. Ez így néz ki:

```{r models, fig.width = 9, fig.height = 3}
p1 = v1 |> 
  mutate(variable = fct_reorder(variable, percentage)) |> 
  ggplot(aes(percentage,variable)) +
  geom_col() +
  theme_few() +
  ylab('') +
  xlim(0,.20) +
  ggtitle('RF predicting sent_rep')

p2 = v2 |> 
  mutate(variable = fct_reorder(variable, percentage)) |> 
  ggplot(aes(percentage,variable)) +
  geom_col() +
  theme_few() +
  ylab('') +
  xlim(0,.20) +
  ggtitle('RF predicting expr_vocab')

p1 + p2

```

Hát ez valakinek biztos jelent valamit!

Mindkét modellra igaz, hogy az első három prediktor megmagyarázza a kimeneti változó varianciájának a felét:

```{r models2}
v1 |>
  mutate(cumsum = cumsum(percentage)) |> 
  select(variable,cumsum) |> 
  kable('simple', digits = 2, caption = 'RF predicting sent_rep')

v2 |>
  mutate(cumsum = cumsum(percentage)) |> 
  select(variable,cumsum) |> 
  kable('simple', digits = 2, caption = 'RF predicting expr_vocab')
```

Szerintem ez az eredmény. Ez a módszer jó abban, hogy nem vesztesz adatokat, és nem baj, hogy minden brutálisan együttáll mindennel, mert erre érzéketlen a random forest. P érték helyett le lehet írni a modellszelekciós kritériumokat és hivatkozgatni a releváns cikkeket.

## Interakciók

Mindkét esetben megnéztem még azt, hogy az első __négy/öt__ változó interakcióban van-e a grouppal. Ehhez bayesi lineáris modellokat és leave-one-out cross validationt használtam. Az első akárhányat kiválasztani önkényes, de itt megint az a probléma, hogy minél több változót teszel a modellba, annál kevesebb megfigyelésre tudod illeszteni, mert a lineáris modell csak olyan megfigyeléseken működik, amikhez megvan minden adat.

Nem találtam interakciókat.

## Összefoglalás

A munkamemória fontosnak tűnik mindkét taszknál (hogy az egyik esetben ezt a forward digit span miért méri jobban, mint a backward, és viszont, az lehet sima zaj?). A group is elég fontos. 

